# ğŸ“˜ Mentor-Scoring-AI

### *AI-Driven Evaluation of Teaching Quality from Recorded Video Sessions*

**Submission for:** *UpSkill India Challenge â€” Techfest IIT Bombay x HCL GUVI*

---

## ğŸš€ Overview

Evaluating teaching quality across large education ecosystems is slow, subjective, and inconsistent.
**Mentor-Scoring-AI** solves this using a **multimodal, fully automated evaluation system** that scores teaching quality directly from recorded lecture videos.

Our AI analyzes:

* Communication clarity
* Engagement & gestures
* Technical depth
* Confidence & pacing
* Interaction quality

Using **video pose detection, audio transcription, and transcript content intelligence** â€” all running **locally**, CPU-friendly, no external LLM or cloud dependency.

---

## ğŸ§  Key Features

### ğŸ”Š **Audio Intelligence (Whisper Speech-to-Text)**

* Local Whisper base model
* Accurate transcription on CPU
* Clean audio extraction using FFmpeg
* Sentence clarity & vocabulary richness scoring

### ğŸ‘ï¸ **Visual + Gesture Intelligence (YOLO Pose)**

* YOLOv11n-Pose â†’ extremely fast pose tracking
* Hand movement â†’ engagement score
* Face visibility & eye-contact cues â†’ confidence score
* Frame sampling optimized for speed

### ğŸ§® **Local Technical Depth Estimation (No LLM Required)**

Your updated code uses **pure local heuristic-based depth scoring**, including:

* Vocabulary diversity
* Rare/long word usage
* Technical keyword detection
* Sentence structure
* Automatic segment-based depth scoring

### ğŸ›ï¸ **Streamlit Evaluation Dashboard**

* Upload video or use URL (YouTube supported)
* Real-time transcript + gesture analysis
* Segment-wise depth scoring
* Final weighted â€œMentor Scoreâ€
* Downloadable evaluation report

---

## ğŸ¯ Why This Matters

Institutions face major challenges:

* Manual evaluation is slow
* Scoring varies between reviewers
* No standardized metrics
* No large-scale automation

**Mentor-Scoring-AI delivers:**

âœ” Consistent, objective scoring
âœ” Fully automated workflow
âœ” Scalable to thousands of videos
âœ” CPU-only & offline-friendly
âœ” Multimodal evaluation similar to human observation

---

## ğŸ—ï¸ System Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       Video Input         â”‚
                    â”‚ (Upload or URL Download)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                 â”‚                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Audio Extract  â”‚ â”‚   Frame Sampler  â”‚ â”‚ Transcript Engine â”‚
        â”‚   (FFmpeg)      â”‚ â”‚   (OpenCV)       â”‚ â”‚    (Whisper)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                 â”‚                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Speech-to-Text  â”‚ â”‚ YOLO Pose Model  â”‚ â”‚ Local Depth Logic â”‚
        â”‚    Whisper      â”‚ â”‚ Gesture/Face     â”‚ â”‚   (Heuristic)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚   Analysis        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                  â”‚                  â”‚                    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼                 â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚     Scoring & Aggregation      â”‚
                     â”‚ (Engagement, Clarity, Depth)   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Streamlit Report   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Repository Structure

```
Mentor-Scoring-AI/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ system_design.md
â”‚   â”œâ”€â”€ architecture.md
â”‚   â””â”€â”€ evaluation_notes.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ transcribe.py
â”‚   â”‚   â”œâ”€â”€ gesture_analysis.py
â”‚   â”‚   â””â”€â”€ depth_analysis.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ ffmpeg_utils.py
â””â”€â”€ models/
    â””â”€â”€ model_download_links.txt
```

---

## âš™ï¸ Tech Stack

### **AI Models**

* Whisper (local CPU transcription)
* YOLOv11n-Pose (gesture and face tracking)
* Local heuristic depth-engine (no LLM)

### **Core Libraries**

* OpenCV
* MoviePy
* YOLO (Ultralytics)
* FFmpeg
* Streamlit (UI)
* FastAPI-style processing structure

---

## ğŸ§ª Evaluation Metrics

Your scoring system exactly matches the hackathon guidelines:

| Skill Metric        | Weight | Source                    |
| ------------------- | ------ | ------------------------- |
| Engagement          | 20%    | YOLO Pose (hands, motion) |
| Communication       | 20%    | Whisper transcript        |
| Technical Depth     | 30%    | Local depth heuristics    |
| Clarity             | 20%    | Transcript complexity     |
| Interaction Quality | 10%    | Eye-contact + pacing      |

---

## ğŸ› ï¸ Quick Start (Development)

### 1ï¸âƒ£ Setup Environment

```bash
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Ensure FFmpeg is Installed

Update the FFmpeg path inside:

```
src/utils/ffmpeg_utils.py
```

### 3ï¸âƒ£ Run Streamlit App

```bash
streamlit run src/app.py
```

### 4ï¸âƒ£ Upload or paste URL â†’ Get instant evaluation

---

## ğŸ¥ Demo Output (Judges Will See)

### âœ” Transcript Summary

* Total word count
* Key topics
* Sentence clarity
* Vocabulary richness

### âœ” Gesture & Engagement Analysis

* Hand movement score
* Eye contact and face visibility
* Confidence cues

### âœ” Technical Depth

* Automatic heuristic-based depth
* Segment-wise scoring
* Explanation + reasoning

### âœ” Final Mentor Score

Weighted blended score with interpretation.

---

## ğŸ“ˆ Innovation & Differentiators

ğŸ”¥ 5Ã— faster processing using YOLOv11n-Pose
ğŸ”¥ Fully local â€” **no API costs, no LLMs, no internet needed**
ğŸ”¥ Local depth analysis engine (unique approach)
ğŸ”¥ Optimized for low-end hardware
ğŸ”¥ URL + file support
ğŸ”¥ Modular AI pipeline

---

## ğŸ§­ Roadmap

* Database storage for mentor scores
* Historical insights & comparison charts
* API endpoints for institution portals
* Real-time evaluation mode (webcam)
* Improvement recommendations using analytics

---

## ğŸ”§ Current Implementation Status

### âœ” Streamlit dashboard connected

### âœ” Whisper transcription working

### âœ” YOLO gesture tracking functional

### âœ” Local depth analysis implemented

### âœ” URL â†’ video â†’ transcript pipeline complete

### â³ Remaining:

1. **Database integration**
2. **Linking dashboard to main website**
3. **Final UI polishing**

---

## ğŸ‘¥ Team

**Abhishek Boyane** â€“ AI/ML
**Ishan Kalhe** â€“ Full-Stack, Backend
**Yash Bhosale** â€“ Vision Processing
**Chetan Patel** â€“ UI/UX

---

## ğŸ“© Contact

**Email:** *[ishankalhe1@gmail.com](mailto:ishankalhe1@gmail.com)*

